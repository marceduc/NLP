{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_F1(df):\n",
    "    #df = dataframe with label and preds = prediction column\n",
    "    #returns F1, precision, recall\n",
    "    TN = (df.loc[df.label == 'O'].preds.values == 'O').sum()\n",
    "    FP = (df.loc[df.label == 'O'].preds.values == 'B-protein').sum()\n",
    "\n",
    "    TP = (df.loc[df.label == 'B-protein'].preds.values == 'B-protein').sum()\n",
    "    FN = (df.loc[df.label == 'B-protein'].preds.values == 'O').sum()\n",
    "\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return(F1,precision,recall)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for validation\n",
    "df = pd.read_csv('uebung5_training.iob', sep = '\\t', names= ['token', 'label'],skip_blank_lines=False)\n",
    "df['token'] = df.token.str.lower()\n",
    "val_idx = int(len(df) * 0.3)\n",
    "train = df[:-val_idx]\n",
    "val = df[-val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to build final dict\n",
    "df = pd.read_csv('uebung5_training.iob', sep = '\\t', names= ['token', 'label'])\n",
    "df['token'] = df.token.str.lower()\n",
    "train = df\n",
    "val = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load gene dict, and stopwords\n",
    "stopwords = pd.read_csv('english_stop_words.txt', sep = '\\t', names= ['stopword'])\n",
    "genenames = pd.read_csv('human-genenames.txt', sep = '\\t', names= ['GenName'])\n",
    "\n",
    "#create set of lower case entries\n",
    "genes = set(genenames.GenName.str.lower().unique())\n",
    "stopwords = set(stopwords.stopword.str.lower().unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add training set labels to dict\n",
    "genes = genes.union(set(train.loc[train.label == 'B-protein'].token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for i in range(len(val)):\n",
    "    if val.token.iloc[i] in stopwords:\n",
    "        preds.append('O')\n",
    "    elif val.token.iloc[i] in genes:\n",
    "        preds.append('B-protein')\n",
    "    else:\n",
    "        preds.append('O')\n",
    "val['preds'] = preds        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7062795408507765, 0.5476439790575917, 0.9942965779467681)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1,precision,recall, = get_F1(val)\n",
    "F1,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add word count column\n",
    "val['count'] = val.groupby('token')['token'].transform('count')\n",
    "# add column with true prediction counts\n",
    "val['result'] = val.label == val.preds\n",
    "val.result = val.result.astype('int')\n",
    "val['true_count'] = val.groupby('token')['result'].transform('sum')\n",
    "# add column with false prediction counts\n",
    "val['false_count'] = val['count'] - val['true_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tokens whith more FP than TP from dict\n",
    "\n",
    "# subset where true value is 'O'\n",
    "val_FP = val.loc[val.label == 'O']\n",
    "# subset where prediction is 'B-protein'\n",
    "val_FP = val_FP.loc[val.preds == 'B-protein']\n",
    "\n",
    "FP_tokens = set(val_FP.token.loc[val_FP.true_count < val_FP.false_count])\n",
    "\n",
    "genes = genes - FP_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new evaluation\n",
    "preds = []\n",
    "\n",
    "for i in range(len(val)):\n",
    "    if val.token.iloc[i] in stopwords:\n",
    "        preds.append('O')\n",
    "    elif val.token.iloc[i] in genes:\n",
    "        preds.append('B-protein')\n",
    "    else:\n",
    "        preds.append('O')\n",
    "val['preds'] = preds\n",
    "F1,precision,recall, = get_F1(val)\n",
    "F1,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new dict to file\n",
    "genenames_extended = pd.DataFrame(list(genes))\n",
    "\n",
    "genenames_extended.to_csv('genenames_extended.txt' ,header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tokens from full training set to genes\n",
    "INPUT_FILE = 'uebung5_test_sample_blind.iob'\n",
    "INPUT_FILE = 'uebung5_training.iob'\n",
    "OUTPUT_FILE = 'predictions.iob'\n",
    "STOP_WORDS_FILE = 'english_stop_words.txt'\n",
    "DICT_FILE = 'genenames_extended.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load gene dict, and stopwords\n",
    "stopwords = pd.read_csv(STOP_WORDS_FILE, sep = '\\t', names= ['stopword'])\n",
    "genenames = pd.read_csv(DICT_FILE, sep = '\\t', names= ['GenName'])\n",
    "\n",
    "#create set of lower case entries\n",
    "genes = set(genenames.GenName.str.lower().unique())\n",
    "stopwords = set(stopwords.stopword.str.lower().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "'''\n",
    "test = pd.read_csv(INPUT_FILE, sep = '\\t',header=None, names= ['token', 'label'] ,skip_blank_lines=False)\n",
    "test['lower'] = test.token.str.lower()\n",
    "\n",
    "\n",
    "preds = []\n",
    "\n",
    "for i in range(len(test)):\n",
    "    if test.lower[i] != test.lower[i]:\n",
    "        preds.append(np.nan)\n",
    "    elif test.lower.iloc[i] in stopwords:\n",
    "        preds.append('O')\n",
    "    elif test.lower.iloc[i] in genes:\n",
    "        preds.append('B-protein')\n",
    "    else:\n",
    "        preds.append('O')\n",
    "        \n",
    "pred_df = pd.DataFrame({'token':test.token.values, 'preds':preds})\n",
    "\n",
    "#pred_df.to_csv(OUTPUT_FILE, sep = '\\t', header = None, index=None)\n",
    "\n",
    "#write lines from df\n",
    "f = open(\"predictions.iob\", \"a\")\n",
    "for i in range(len(pred_df)):\n",
    "    if(test.lower[i] != test.lower[i]):\n",
    "        f.write('\\n')\n",
    "    else:\n",
    "        f.write(pred_df.token[i] + '\\t' + pred_df.preds[i] + '\\n')\n",
    "f.close()\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INPUT_FILE, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = [line.strip() for line in lines]\n",
    "token = [str.split(line, '\\t')[0] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(OUTPUT_FILE, \"w\")\n",
    "for tok in token:\n",
    "    if(tok == ''):\n",
    "        f.write('\\n')\n",
    "    elif(tok.lower() in stopwords):\n",
    "        f.write(tok + '\\t' + 'O' + '\\n')\n",
    "    elif(tok.lower() in genes):\n",
    "        f.write(tok + '\\t' + 'B-protein' +'\\n')\n",
    "    else:\n",
    "        f.write(tok + '\\t' + 'O' + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .py Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    INPUT_FILE = sys.argv[1]\n",
    "    OUTPUT_FILE = sys.argv[2]\n",
    "    STOP_WORDS_FILE = 'english_stop_words.txt'\n",
    "    DICT_FILE = 'genenames_extended.txt'\n",
    "    \n",
    "    #load gene dict, and stopwords\n",
    "    stopwords = pd.read_csv(STOP_WORDS_FILE, sep = '\\t', names= ['stopword'])\n",
    "    genenames = pd.read_csv(DICT_FILE, sep = '\\t', names= ['GenName'])\n",
    "\n",
    "    #create set of lower case entries\n",
    "    genes = set(genenames.GenName.str.lower().unique())\n",
    "    stopwords = set(stopwords.stopword.str.lower().unique())\n",
    "    \n",
    "    with open(INPUT_FILE, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    lines = [line.strip() for line in lines]\n",
    "    token = [str.split(line, '\\t')[0] for line in lines]\n",
    "    \n",
    "    \n",
    "    f = open(OUTPUT_FILE, \"w\")\n",
    "    for tok in token:\n",
    "        if(tok == ''):\n",
    "            f.write('\\n')\n",
    "        elif(tok.lower() in stopwords):\n",
    "            f.write(tok + '\\t' + 'O' + '\\n')\n",
    "        elif(tok.lower() in genes):\n",
    "            f.write(tok + '\\t' + 'B-protein' +'\\n')\n",
    "        else:\n",
    "            f.write(tok + '\\t' + 'O' + '\\n')\n",
    "    f.close()\n",
    "    \n",
    "    '''\n",
    "        # load classification data\n",
    "    test = pd.read_csv(INPUT_FILE, sep = '\\t',header=None, names= ['token', 'label'], skip_blank_lines=False)\n",
    "    test['lower'] = test.token.str.lower()\n",
    "    \n",
    "    # make predictions\n",
    "    preds = []\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        if test.lower[i] != test.lower[i]:\n",
    "            preds.append(np.nan)\n",
    "        elif test.lower.iloc[i] in stopwords:\n",
    "            preds.append('O')\n",
    "        elif test.lower.iloc[i] in genes:\n",
    "            preds.append('B-protein')\n",
    "        else:\n",
    "            preds.append('O')\n",
    "    \n",
    "    pred_df = pd.DataFrame({'token':test.token.values, 'preds':preds})\n",
    "    pred_df = pred_df.fillna('')\n",
    "    pred_df.to_csv(OUTPUT_FILE, sep = '\\t', header = None, index=None)\n",
    "    '''\n",
    "\n",
    "    \n",
    "main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOLD_STANDARD = 'uebung5_training.iob'\n",
    "PREDICTION_FILE = 'predictions.iob'\n",
    "\n",
    "\n",
    "with open(GOLD_STANDARD, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = [line.strip() for line in lines]\n",
    "labels = [str.split(line, '\\t')[1] if len(line) is not 0 else str.split(line, '\\t')[0] for line in lines]\n",
    "token = [str.split(line, '\\t')[0] for line in lines]\n",
    "\n",
    "with open(PREDICTION_FILE, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [line.strip() for line in lines]\n",
    "preds = [str.split(line, '\\t')[1] if len(line) is not 0 else str.split(line, '\\t')[0] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = {}\n",
    "FP = {}\n",
    "\n",
    "TP = {}\n",
    "FN = {}\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    \n",
    "    if labels[i] == '':\n",
    "        if preds[i] == '':\n",
    "            next\n",
    "        else:\n",
    "            print(\"non matching empty line at row \" + str(i))\n",
    "            break\n",
    "    elif labels[i] == 'O':\n",
    "        if labels[i] == preds[i]:\n",
    "            if token[i] in TN:\n",
    "                TN.get(token[i]).append(i)\n",
    "            else:\n",
    "                TN[token[i]] = [i]\n",
    "        else:\n",
    "            if token[i] in FP:\n",
    "                FP.get(token[i]).append(i)\n",
    "            else:\n",
    "                FP[token[i]] = [i]\n",
    "                \n",
    "    elif labels[i] == 'B-protein':\n",
    "        if labels[i] == preds[i]:\n",
    "            if token[i] in TP:\n",
    "                TP.get(token[i]).append(i)\n",
    "            else:\n",
    "                TP[token[i]] = [i]\n",
    "        else:\n",
    "            if token[i] in FN:\n",
    "                FN.get(token[i]).append(i)\n",
    "            else:\n",
    "                FN[token[i]] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512, 110, 173088, 66)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_count = sum([len(value) for key, value in TP.items()])\n",
    "FP_count = sum([len(value) for key, value in FP.items()])\n",
    "\n",
    "TN_count = sum([len(value) for key, value in TN.items()])\n",
    "FN_count = sum([len(value) for key, value in FN.items()])\n",
    "\n",
    "TP_count,FP_count,TN_count,FN_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9450000000000001, 0.9321824907521579, 0.9581749049429658)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = TP_count / (TP_count + FP_count)\n",
    "recall = TP_count / (TP_count + FN_count)\n",
    "\n",
    "F1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "F1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP   R, 22853, 141060\n",
      "FP   AF, 30414, 30446\n",
      "FP   porphyrin, 37792, 37796\n",
      "FP   p50, 40994\n",
      "FP   b6, 41022\n",
      "FP   Shc, 49200\n",
      "FP   rev, 52473\n",
      "FP   W, 52487\n",
      "FP   Y, 52489\n",
      "FP   P1, 52948\n",
      "FP   P2, 52950\n",
      "FP   PR, 55545, 146765, 146789\n",
      "FP   D1, 55986\n",
      "FP   Rev, 60007\n",
      "FP   Cas, 68112\n",
      "FP   Q, 75218\n",
      "FP   CAT, 78031, 127232\n",
      "FP   L1, 82553, 138422\n",
      "FP   HA, 84069\n",
      "FP   PTH, 84146, 87257, 103011\n",
      "FP   IF, 86551\n",
      "FP   AP, 87270\n",
      "FP   AFP, 87789\n",
      "FP   F1, 93465\n",
      "FP   Ro, 94804\n",
      "FP   La, 94806\n",
      "FP   glucagon, 97063\n",
      "FP   CAP, 97453\n",
      "FP   TR, 98261\n",
      "FP   T, 99155\n",
      "FP   SAP, 103360\n",
      "FP   PRC, 115744\n",
      "FP   CBF, 118223\n",
      "FP   PML, 118629\n",
      "FP   RT, 118682\n",
      "FP   R1, 124995\n",
      "FP   R2, 124997\n",
      "FP   E2, 137415, 181282\n",
      "FP   HD, 137460\n",
      "FP   Max, 137583\n",
      "FP   Z, 141058\n",
      "FP   endonuclease, 155262\n",
      "FP   A, 157570\n",
      "FP   GAP, 157919\n",
      "FP   cytokine, 161773\n",
      "FP   LT, 162892\n",
      "FP   P3, 163657\n",
      "FP   tip, 163856\n",
      "FP   gpI, 171204, 171218\n",
      "FP   en, 174070\n",
      "FP   E1, 176076, 176084, 180418, 181280\n",
      "FP   carboxyhemoglobin, 179584\n",
      "FP   R, 22853, 141060\n",
      "FP   AF, 30414, 30446\n",
      "FP   porphyrin, 37792, 37796\n",
      "FP   p50, 40994\n",
      "FP   b6, 41022\n",
      "FP   Shc, 49200\n",
      "FP   rev, 52473\n",
      "FP   W, 52487\n",
      "FP   Y, 52489\n",
      "FP   P1, 52948\n",
      "FP   P2, 52950\n",
      "FP   PR, 55545, 146765, 146789\n",
      "FP   D1, 55986\n",
      "FP   Rev, 60007\n",
      "FP   Cas, 68112\n",
      "FP   Q, 75218\n",
      "FP   CAT, 78031, 127232\n",
      "FP   L1, 82553, 138422\n",
      "FP   HA, 84069\n",
      "FP   PTH, 84146, 87257, 103011\n",
      "FP   IF, 86551\n",
      "FP   AP, 87270\n",
      "FP   AFP, 87789\n",
      "FP   F1, 93465\n",
      "FP   Ro, 94804\n",
      "FP   La, 94806\n",
      "FP   glucagon, 97063\n",
      "FP   CAP, 97453\n",
      "FP   TR, 98261\n",
      "FP   T, 99155\n",
      "FP   SAP, 103360\n",
      "FP   PRC, 115744\n",
      "FP   CBF, 118223\n",
      "FP   PML, 118629\n",
      "FP   RT, 118682\n",
      "FP   R1, 124995\n",
      "FP   R2, 124997\n",
      "FP   E2, 137415, 181282\n",
      "FP   HD, 137460\n",
      "FP   Max, 137583\n",
      "FP   Z, 141058\n",
      "FP   endonuclease, 155262\n",
      "FP   A, 157570\n",
      "FP   GAP, 157919\n",
      "FP   cytokine, 161773\n",
      "FP   LT, 162892\n",
      "FP   P3, 163657\n",
      "FP   tip, 163856\n",
      "FP   gpI, 171204, 171218\n",
      "FP   en, 174070\n",
      "FP   E1, 176076, 176084, 180418, 181280\n",
      "FP   carboxyhemoglobin, 179584\n",
      "\n",
      "\n",
      "True Positives     1512\n",
      "False Positives     110\n",
      "True Negatives     173088\n",
      "Precision     0.9321824907521579\n",
      "Recall     0.9581749049429658\n",
      "F1 Score     0.9450000000000001\n"
     ]
    }
   ],
   "source": [
    "for key, value in FN.items():\n",
    "    line = [key]\n",
    "    ids = [str(i) for i in value]\n",
    "    line.extend(ids)\n",
    "    print(\"FP   \" + ', '.join(line))\n",
    "    \n",
    "for key, value in FN.items():\n",
    "    line = [key]\n",
    "    ids = [str(i) for i in value]\n",
    "    line.extend(ids)\n",
    "    print(\"FP   \" + ', '.join(line))\n",
    "    \n",
    "print('\\n')\n",
    "print('True Positives     ' + str(TP_count))\n",
    "print('False Positives     ' + str(FP_count))\n",
    "print('True Negatives     ' + str(TN_count))\n",
    "print('Precision     ' + str(precision))\n",
    "print('Recall     ' + str(recall))\n",
    "print('F1 Score     ' + str(F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uebung5-eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def main():\n",
    "    \n",
    "    GOLD_STANDARD = sys.argv[1]\n",
    "    PREDICTION_FILE = sys.argv[2]\n",
    "\n",
    "    # read true labels, tokens and predictions\n",
    "\n",
    "    with open(GOLD_STANDARD, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    lines = [line.strip() for line in lines]\n",
    "    labels = [str.split(line, '\\t')[1] if len(line) is not 0 else str.split(line, '\\t')[0] for line in lines]\n",
    "    token = [str.split(line, '\\t')[0] for line in lines]\n",
    "\n",
    "    with open(PREDICTION_FILE, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    lines = [line.strip() for line in lines]\n",
    "    preds = [str.split(line, '\\t')[1] if len(line) is not 0 else str.split(line, '\\t')[0] for line in lines]\n",
    "\n",
    "    # create dictionary of TP,FP, TN,TP with tokens and ids\n",
    "\n",
    "    TN = {}\n",
    "    FP = {}\n",
    "\n",
    "    TP = {}\n",
    "    FN = {}\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "\n",
    "        if labels[i] == '':\n",
    "            if preds[i] == '':\n",
    "                next\n",
    "            else:\n",
    "                print(\"non matching empty line at row \" + str(i))\n",
    "                break\n",
    "        elif labels[i] == 'O':\n",
    "            if labels[i] == preds[i]:\n",
    "                if token[i] in TN:\n",
    "                    TN.get(token[i]).append(i)\n",
    "                else:\n",
    "                    TN[token[i]] = [i]\n",
    "            else:\n",
    "                if token[i] in FP:\n",
    "                    FP.get(token[i]).append(i)\n",
    "                else:\n",
    "                    FP[token[i]] = [i]\n",
    "\n",
    "        elif labels[i] == 'B-protein':\n",
    "            if labels[i] == preds[i]:\n",
    "                if token[i] in TP:\n",
    "                    TP.get(token[i]).append(i)\n",
    "                else:\n",
    "                    TP[token[i]] = [i]\n",
    "            else:\n",
    "                if token[i] in FN:\n",
    "                    FN.get(token[i]).append(i)\n",
    "                else:\n",
    "                    FN[token[i]] = [i]\n",
    "\n",
    "\n",
    "    # count class lengths\n",
    "    TP_count = sum([len(value) for key, value in TP.items()])\n",
    "    FP_count = sum([len(value) for key, value in FP.items()])\n",
    "\n",
    "    TN_count = sum([len(value) for key, value in TN.items()])\n",
    "    FN_count = sum([len(value) for key, value in FN.items()])\n",
    "\n",
    "    # calculate results\n",
    "\n",
    "    precision = TP_count / (TP_count + FP_count)\n",
    "    recall = TP_count / (TP_count + FN_count)\n",
    "\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    # print results\n",
    "\n",
    "    for key, value in FN.items():\n",
    "        line = [key]\n",
    "        ids = [str(i) for i in value]\n",
    "        line.extend(ids)\n",
    "        print(\"FP   \" + ', '.join(line))\n",
    "    \n",
    "    print('\\n')\n",
    "\n",
    "    for key, value in FN.items():\n",
    "        line = [key]\n",
    "        ids = [str(i) for i in value]\n",
    "        line.extend(ids)\n",
    "        print(\"FP   \" + ', '.join(line))\n",
    "\n",
    "    print('\\n')\n",
    "    print('True Positives     ' + str(TP_count))\n",
    "    print('False Positives     ' + str(FP_count))\n",
    "    print('False Negatives     ' + str(FN_count))\n",
    "    print('Precision     ' + str(precision))\n",
    "    print('Recall     ' + str(recall))\n",
    "    print('F1 Score     ' + str(F1))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
