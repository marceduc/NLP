{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M61b2MANhdt_"
   },
   "outputs": [],
   "source": [
    "PATH_TR = 'uebung6.train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XjpU0Z-4ks4W",
    "outputId": "13707498-2c4f-448a-f0b8-e06611521b5e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn_crfsuite\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "#from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOu1XE8dOOs3"
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSUsHfU8hb2F"
   },
   "outputs": [],
   "source": [
    "with open(PATH_TR, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = [line.strip() for line in lines]\n",
    "token = ['<START>' if str.split(line, ' ')[0] == '' else str.split(line, ' ')[0] for line in lines]\n",
    "tag = ['<START>' if str.split(line, ' ')[0] == '' else str.split(line, ' ')[1] for line in lines]\n",
    "label = ['<START>' if str.split(line, ' ')[0] == '' else str.split(line, ' ')[2] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdaQzrNwQ5N1"
   },
   "outputs": [],
   "source": [
    "def to_str_token(token, word = True):\n",
    "  token_seq = \" \".join(token)\n",
    "  \n",
    "  if(word):\n",
    "    token_seq = re.sub('-DOCSTART- <START>', '',token_seq)\n",
    "  \n",
    "  else:\n",
    "    token_seq = re.sub('X <START>', '',token_seq)\n",
    "  \n",
    "  sentence_tok = token_seq.split(\"<START>\")\n",
    "  sentence_tok = [s.strip() for s in sentence_tok]\n",
    "  sentence_tok = [s.split(' ') for s in sentence_tok]\n",
    "  sentence_list =  [list(filter(None, s)) for s in sentence_tok]\n",
    "  sentence_list = list(filter(None, sentence_tok))\n",
    "  \n",
    "  return(sentence_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JrHwjhqFRtx-",
    "outputId": "74c764bc-f2fc-4037-ce5d-7fae2ed26b33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 12000, 12000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tok = to_str_token(token)[:-1]\n",
    "sent_tag = to_str_token(tag, False)[:-1]\n",
    "sent_lab = to_str_token(label, False)[:-1]\n",
    "\n",
    "\n",
    "len(sent_tok), len(sent_tag), len(sent_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NT5in6zLxu8"
   },
   "outputs": [],
   "source": [
    "train_sents = []\n",
    "\n",
    "for i in range(len(sent_tok)):\n",
    "  s = []\n",
    "  for t,p,y in zip(sent_tok[i], sent_tag[i], sent_lab[i]):\n",
    "    s.append((t,p,y))\n",
    "  train_sents.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "e9aSq0aYQ47g",
    "outputId": "6faac08e-a6ce-4e8b-d0bd-1aeef5d5246b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.2 s, sys: 380 ms, total: 25.5 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"crf_model.p\"\n",
    "pickle.dump(crf, open(model_file, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2oX1obLPVcA"
   },
   "outputs": [],
   "source": [
    "PATH_VAL = 'uebung6.val'\n",
    "model_file = \"crf_model.p\"\n",
    "\n",
    "with open(PATH_VAL, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = [line.strip() for line in lines]\n",
    "token = ['<START>' if str.split(line, ' ')[0] == '' else str.split(line, ' ')[0] for line in lines]\n",
    "tag = ['<START>' if str.split(line, ' ')[0] == '' else str.split(line, ' ')[1] for line in lines]\n",
    "label = ['<START>' if str.split(line, ' ')[0] == '' else str.split(line, ' ')[2] for line in lines]\n",
    "\n",
    "sent_tok = to_str_token(token)[:-1]\n",
    "sent_tag = to_str_token(tag, False)[:-1]\n",
    "sent_lab = to_str_token(label, False)[:-1]\n",
    "\n",
    "\n",
    "len(sent_tok), len(sent_tag), len(sent_lab)\n",
    "\n",
    "\n",
    "val_sents = []\n",
    "\n",
    "for i in range(len(sent_tok)):\n",
    "  s = []\n",
    "  for t,p,y in zip(sent_tok[i], sent_tag[i], sent_lab[i]):\n",
    "    s.append((t,p,y))\n",
    "  val_sents.append(s)\n",
    "\n",
    "\n",
    "X_val = [sent2features(s) for s in val_sents]\n",
    "y_val = [sent2labels(s) for s in val_sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1nGyJYORekF"
   },
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf =  pickle.load(open(model_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zXsstmFnRiZ0",
    "outputId": "c69590a5-8fa4-499e-a7c8-c193c057d314"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591408698962599"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_val)\n",
    "metrics.flat_f1_score(y_val, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaS2_g8Uf_Km"
   },
   "outputs": [],
   "source": [
    "output_lines = []\n",
    "j = 0 \n",
    "\n",
    "for i in range(len(token)):\n",
    "  if token[i] == '-DOCSTART-':\n",
    "    output_lines.append('-DOCSTART- X X O')\n",
    "  elif token[i] == '<START>':\n",
    "    output_lines.append('')\n",
    "  else:\n",
    "    txt = token[i] + \" \" + tag[i] + \" \" + y_pred[j]\n",
    "    j += 1\n",
    "    output_lines.append(txt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MLBclw7-SlEu",
    "outputId": "6513ca86-6f98-44c8-9c87-700fa832eaa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56246, 56246)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_lines), len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vk8i0Lm6C-9e"
   },
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"output_file.iob\"\n",
    "#OUTPUT_FILE = \"output_file.iob\"\n",
    "with open(OUTPUT_FILE,mode = 'w') as f: \n",
    "    f.write(\"\\n\".join(output_lines))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CRF_NER.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
